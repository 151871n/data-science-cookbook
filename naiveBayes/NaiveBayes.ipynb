{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos criar a classe Naive Bayes para representar o nosso algoritmo.\n",
    "O método **__init__** representa o construtor, inicializando as variáveis do nosso modelo.\n",
    "O modelo gerado é formado basicamente pela frequência das palavras, que em nosso caso, representa os possíveis valores de cada feature e label.\n",
    "\n",
    "* O defaultdict é utilizado para inicializar nosso dicionário com valores default, no caso 0 (int), para chaves que tentamos acessar e ainda não foram adicionadas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from functools import reduce\n",
    "import math\n",
    "\n",
    "class NaiveBayes:\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self.freqFeature = defaultdict(int)\n",
    "        self.freqLabel = defaultdict(int)\n",
    "\n",
    "        # condFreqFeature[label][feature]\n",
    "        self.condFreqFeature = defaultdict(lambda: defaultdict(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo\n",
    "\n",
    "Como o modelo é representado basicamente pela frequência das palavras, precisamos categorizar os possíveis valores das features. Após esse processo, fazemos a contagem.\n",
    "\n",
    "* countFrequencies: faz a contagem que cada valor de feature e label aparecem em todo o dataset de treino, independentemente.\n",
    "* countCondFrequencies: faz a contagem que cada valor de feature aparece para cada possível label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def countFrequencies(self):\n",
    "        allFeatures = reduce(lambda x, y: x+y, self.dataSet_x)\n",
    "\n",
    "        for f in allFeatures:\n",
    "            self.freqFeature[f] += 1\n",
    "\n",
    "        for l in self.dataSet_y:\n",
    "            self.freqLabel[l] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def countCondFrequencies(self):\n",
    "\n",
    "        dataSet = list(zip(self.dataSet_x, self.dataSet_y)) #A partir de python 3, zip retorna object. Entao mudo para list\n",
    "\n",
    "        for t in dataSet:\n",
    "            for f in t[0]:\n",
    "                # condFreqFeature[label][feature]\n",
    "                self.condFreqFeature[t[1]][f] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(self, dataSet_x, dataSet_y):\n",
    "\n",
    "        self.dataSet_x = dataSet_x\n",
    "        self.dataSet_y = dataSet_y\n",
    "\n",
    "        self.countFrequencies()\n",
    "        self.countCondFrequencies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " def probLikelihood(self, f, l, vocabulary):\n",
    "        laplace = 1\n",
    "\n",
    "        condFreq = self.condFreqFeature[l][f]\n",
    "        prob = (float)(condFreq + laplace) / (self.freqLabel[l] + vocabulary)\n",
    "\n",
    "        # print l + \" - \" + f + \" = \" + str(prob)\n",
    "\n",
    "        return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(self, dataSet_x):\n",
    "\n",
    "        # Correcao de Laplace\n",
    "        # P( f | l) = (freq( f | l ) + laplace*) / ( freq(l)** + qnt(distinct(f))*** )\n",
    "        #\n",
    "        # * -> laplace smoothing: add 1\n",
    "        # ** -> Frequencia com que o valor de label aparece\n",
    "        # *** -> Quantidade de features distintas\n",
    "        #\n",
    "\n",
    "        # Devido a possibilidade de underflow de pontos flutuantes, eh interessante fazer\n",
    "        # P(x1|l)*P(x2|l) ... -> Log(P(x1|l)) + Log(P(x2|l)) ...\n",
    "\n",
    "\n",
    "\n",
    "        probs = []\n",
    "        totalTuples = len(self.dataSet_y)\n",
    "        vocabulary = len(self.freqFeature)\n",
    "\n",
    "        #Cada tupla\n",
    "        for index, t in enumerate(dataSet_x):\n",
    "            probs.append(defaultdict(float))\n",
    "\n",
    "            #Cada label\n",
    "            for l in self.dataSet_y:\n",
    "                prob = 0.0\n",
    "\n",
    "                #Cada feature\n",
    "                for f in t:\n",
    "                    prob += math.log10(self.probLikelihood(f, l, vocabulary))\n",
    "\n",
    "                prob += (self.freqLabel[l] / totalTuples)\n",
    "\n",
    "                probs[index][l] = prob\n",
    "\n",
    "        return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Car dataset\n",
    "# Attribute Information:\n",
    "#\n",
    "# Class Values:\n",
    "#\n",
    "# unacc, acc, good, vgood\n",
    "#\n",
    "# Attributes:\n",
    "#\n",
    "# buying: vhigh, high, med, low.\n",
    "# maint: vhigh, high, med, low.\n",
    "# doors: 2, 3, 4, 5more.\n",
    "# persons: 2, 4, more.\n",
    "# lug_boot: small, med, big.\n",
    "# safety: low, med, high.\n",
    "\n",
    "#Retur dataset\n",
    "def readFile(path):\n",
    "    rawDataset = open(path, 'r')\n",
    "\n",
    "\n",
    "    suffix = ['_buy', '_maint', '_doors', '_pers', '_lug', '_safety', '_class']\n",
    "\n",
    "    dataset = []\n",
    "\n",
    "    rawDataset.seek(0)\n",
    "    for line in rawDataset:\n",
    "    \tl = line.split(',')\n",
    "        l[-1] = l[-1].replace(\"\\n\", \"\")\n",
    "        newTuple = map(lambda (x,y): x+y, zip( l , suffix))\n",
    "        dataset.append( newTuple )\n",
    "\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: 'carData.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mIOError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-9e90db58fbe0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataSet_y_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-8-9e90db58fbe0>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mpreparedDataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreadFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'carData.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreparedDataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-4384c997e707>\u001b[0m in \u001b[0;36mreadFile\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m#Retur dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mreadFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mrawDataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'carData.txt'"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "\n",
    "    preparedDataset = readFile('carData.txt')\n",
    "\n",
    "    random.shuffle(preparedDataset)\n",
    "\n",
    "    dataset = []\n",
    "    #Features\n",
    "    dataset.append([])\n",
    "    #Label\n",
    "    dataset.append([])\n",
    "\n",
    "    for t in preparedDataset:\n",
    "        dataset[0].append(t[:-1])\n",
    "        dataset[1].append(t[-1])\n",
    "\n",
    "\n",
    "    dataSet_x = dataset[0]\n",
    "    dataSet_y = dataset[1]\n",
    "\n",
    "    nTuples = len(dataSet_x)\n",
    "\n",
    "    nToTrain = int(nTuples * 0.7)\n",
    "\n",
    "    dataSet_x_train = dataSet_x[:nToTrain]\n",
    "    dataSet_y_train = dataSet_y[:nToTrain]\n",
    "\n",
    "    dataSet_x_test = dataSet_x[nToTrain:]\n",
    "    dataSet_y_test = dataSet_y[nToTrain:]\n",
    "\n",
    "    naive = NaiveBayes()\n",
    "\n",
    "    naive.train(dataSet_x_train, dataSet_y_train)\n",
    "\n",
    "    accuracy = 0.0\n",
    "\n",
    "    results = naive.predict(dataSet_x_test)\n",
    "\n",
    "    for index, r in enumerate(results):\n",
    "        yPredicted = max(r, key=r.get)\n",
    "        y = dataSet_y_test[index]\n",
    "        \n",
    "        if(y == yPredicted):\n",
    "            accuracy += 1.0\n",
    "\n",
    "    print accuracy / len(dataSet_y_test)\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
